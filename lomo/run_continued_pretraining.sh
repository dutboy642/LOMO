#!/bin/bash

set -x

# Set default GPU if not specified
if [ -z "$CUDA_VISIBLE_DEVICES" ]; then
    export CUDA_VISIBLE_DEVICES="0"
    echo "âš ï¸  CUDA_VISIBLE_DEVICES not set, defaulting to GPU 0"
fi

# Validate CUDA_VISIBLE_DEVICES format
if [[ ! "$CUDA_VISIBLE_DEVICES" =~ ^[0-9]+(,[0-9]+)*$ ]]; then
    echo "âŒ Invalid CUDA_VISIBLE_DEVICES format: $CUDA_VISIBLE_DEVICES"
    echo "   Expected format: 0 or 0,1 or 0,1,2,3"
    export CUDA_VISIBLE_DEVICES="0"
    echo "   Using default: GPU 0"
fi

# Generate random port for DeepSpeed
port=$(shuf -i25000-30000 -n1)

echo "==================================="
echo "LOMO Continued Pretraining Script"
echo "==================================="
echo "Port: $port"
echo "Config: config/args_continued_pretraining.yaml"
echo "GPUs: $CUDA_VISIBLE_DEVICES"
echo "==================================="

# Create data directory if it doesn't exist
mkdir -p data

# Check if dataset manager exists and use it
if [ -f "src/dataset_manager.py" ]; then
    echo "ðŸ“‹ Checking dataset status..."
    python src/dataset_manager.py --list
    echo ""
    
    # Extract dataset name from config
    DATASET_NAME=$(grep "dataset_name:" config/args_continued_pretraining.yaml | sed "s/.*: *'//" | sed "s/'.*//")
    echo "ðŸŽ¯ Target dataset: $DATASET_NAME"
    
    # Auto-download if dataset doesn't exist
    if ! python -c "
import sys
sys.path.append('src')
from dataset_manager import DatasetManager
manager = DatasetManager()
info = manager.check_dataset_exists('$DATASET_NAME')
exit(0 if info['exists'] else 1)
"; then
        echo "ðŸ“¥ Dataset not found. Auto-downloading..."
        python src/dataset_manager.py --download "$DATASET_NAME"
        
        if [ $? -ne 0 ]; then
            echo "âŒ Failed to download dataset. Creating sample instead..."
            if [[ "$DATASET_NAME" == *"custom"* ]]; then
                python src/dataset_manager.py --create-sample custom_text
                # Update config to use sample
                sed -i "s/dataset_name: .*/dataset_name: 'custom_text'/" config/args_continued_pretraining.yaml
            else
                echo "âŒ Cannot create sample for $DATASET_NAME. Please prepare dataset manually."
                exit 1
            fi
        fi
    else
        echo "âœ… Dataset already exists!"
    fi
else
    echo "âš ï¸  Dataset manager not found. Creating basic sample..."
    # Create a basic sample if dataset manager is not available
    if [ ! -f "data/custom_text.txt" ]; then
        cat > data/custom_text.txt << 'EOF'
ÄÃ¢y lÃ  má»™t vÄƒn báº£n máº«u Ä‘á»ƒ thá»±c hiá»‡n continued pretraining.
Continued pretraining giÃºp mÃ´ hÃ¬nh há»c thÃªm kiáº¿n thá»©c vá» má»™t lÄ©nh vá»±c cá»¥ thá»ƒ.

QuÃ¡ trÃ¬nh nÃ y khÃ¡c vá»›i fine-tuning á»Ÿ chá»—:
- KhÃ´ng cáº§n format question/answer
- Train trÃªn raw text Ä‘á»ƒ há»c ngÃ´n ngá»¯ vÃ  kiáº¿n thá»©c domain
- ThÆ°á»ng dÃ¹ng learning rate tháº¥p hÆ¡n

VÃ­ dá»¥ vá» continued pretraining:
- Train mÃ´ hÃ¬nh tiáº¿ng Anh trÃªn corpus tiáº¿ng Viá»‡t
- Train mÃ´ hÃ¬nh general trÃªn dá»¯ liá»‡u y khoa
- Train mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u phÃ¡p lÃ½

Má»—i Ä‘oáº¡n text Ä‘Æ°á»£c tokenize vÃ  model há»c predict token tiáº¿p theo.
Äiá»u nÃ y giÃºp model hiá»ƒu ngá»¯ cáº£nh vÃ  ngá»¯ phÃ¡p cá»§a domain má»›i.

Vá»›i LOMO optimizer, ta cÃ³ thá»ƒ train full parameters vá»›i memory tháº¥p.
ÄÃ¢y lÃ  Æ°u Ä‘iá»ƒm lá»›n so vá»›i cÃ¡c optimizer truyá»n thá»‘ng nhÆ° AdamW.

Káº¿t quáº£ cuá»‘i cÃ¹ng lÃ  má»™t model Ä‘Æ°á»£c adapt cho domain cá»¥ thá»ƒ.
Model nÃ y sáº½ generate text tá»‘t hÆ¡n cho domain Ä‘Ã³.
EOF
        echo "ðŸ“„ Sample text file created at data/custom_text.txt"
        sed -i "s/dataset_name: .*/dataset_name: 'custom_text'/" config/args_continued_pretraining.yaml
    fi
fi

echo ""
echo "ðŸš€ Starting continued pretraining..."
echo "ðŸ“Š Final dataset status:"
if [ -f "src/dataset_manager.py" ]; then
    python src/dataset_manager.py --list
fi

# Run continued pretraining
echo "ðŸš€ Starting DeepSpeed training..."
echo "Command: deepspeed --master_port $port --include localhost:$CUDA_VISIBLE_DEVICES src/train_lomo_continued_pretraining.py config/args_continued_pretraining.yaml"
echo ""

# Check number of GPUs and adjust include parameter
IFS=',' read -ra GPU_ARRAY <<< "$CUDA_VISIBLE_DEVICES"
GPU_COUNT=${#GPU_ARRAY[@]}

if [ $GPU_COUNT -eq 1 ]; then
    # Single GPU training
    deepspeed --master_port "$port" \
        --include localhost:${CUDA_VISIBLE_DEVICES} \
        src/train_lomo_continued_pretraining.py \
        config/args_continued_pretraining.yaml
else
    # Multi-GPU training
    deepspeed --master_port "$port" \
        --include localhost:${CUDA_VISIBLE_DEVICES} \
        src/train_lomo_continued_pretraining.py \
        config/args_continued_pretraining.yaml
fi

exit_code=$?
if [ $exit_code -eq 0 ]; then
    echo "==================================="
    echo "âœ… Continued pretraining completed successfully!"
    echo "ðŸ“ Check outputs/ directory for results"
    echo "==================================="
else
    echo "==================================="
    echo "âŒ Training failed with exit code: $exit_code"
    echo "ðŸ“ Check logs above for error details"
    echo "==================================="
    exit $exit_code
fi